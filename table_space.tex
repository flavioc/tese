
In this chapter, the table space organization for both variant and subsumption tabling
engines are described. First, the variant table space for both SLG-WAM and YapTab is
explained. Because they share a lot of similarities, the description covers the common
ground between the two systems. Next, we explore two well-known mechanisms that modify
the previous table space for call by subsumption. Those two mechanisms have already been
implemented in XSB \cite{Rao-96, Johnson-99}.

\section{Table Space} \label{sec:table_space}

Implementing a tabling engine on a Prolog system involves the design of compact and time efficient data structures
to organize the table space. The table space is heavily used throughout the evaluation process in various operations:

\begin{itemize}
  \item to lookup if a subgoal is in the table, and if not insert it;
  \item to verify whether a newly found answer is already in the table, and if not insert it;
  \item to retrieve answers for consumer nodes.
\end{itemize}

\subsection{Tries}

Clearly, the success of tabling is highly dependent on the data structures used.
Both Yap \cite{Rocha-00a} and XSB \cite{RamakrishnanIV-95} use a trie-based approach.

Tries were initially proposed to index dictionaries \cite{Fredkin-62} and have since been generalized to index recursive data structures
such as terms. The essential idea underlying a trie is to partition a set $T$ of terms based upon their structure,
in such a way that common term prefixes are represented only once.

A trie is a tree-structured automaton with the root as the start state and each leaf state associated with a term in $T$.
Each state specifies the position to be inspected in the input term on reaching that state.
The outgoing transitions specify the function symbols expected at that position.
A transition is taken if the current symbol in the input term matches the symbol of the transition.
If we recursively reach a leaf state we say that the input term \textit{matches} the term represented by the leaf state.
A complete path, from the root to a leaf, corresponds to a pre-order traversal of the matching term.
If no transition can be taken, the lookup operation fails. On the other hand, for an insert operation
we add a new outgoing transition for the current input symbol and a new node, which is linked to this transition.
To complete the insert operation, we consume the rest of the input term, until a leaf node is created that represents
the newly inserted term.

Given the nature of tries, the following conclusions can be made:

\begin{itemize}
  \item the lookup/insert operation can be done in a single pass through a term. If the lookup fails, it is possible
  to complete an insert operation using the last lookup state;
  \item the efficiency and memory consumption of a
  particular trie depends on the percentage of terms that have common prefixes.
\end{itemize}

When creating transitions for variables, we use the format outlined by Bachmair \textit{et al.} \cite{Bachmair-93},
described in Section \ref{sec:variant_tabling}.

Figure~\ref{fig:tries_use} shows a trie with three terms. First, in (a) the trie is represented by a \textit{root node} and has
no terms. Next, in (b) the term \texttt{t(X,a)} is inserted and three nodes are created that represent each part of the term.
In (c) a new term, \texttt{u(X,b,Y)} is inserted. This new term differs from the first one and a new distinct branch is created.
Finally, in (d), the term \texttt{t(Y,1)} is inserted and only a new node needs to be created as this term shares
two prefix nodes with \texttt{t(X,a)}.

\begin{figure}[ht]
  \centering
    \includegraphics[scale=0.6]{tries.pdf}
  \caption{Using tries to represent terms.}
  \label{fig:tries_use}
\end{figure}

Yap and XSB use two levels of tries to implement the table space (see Figure~\ref{fig:table_space_tries}):

\begin{itemize}
  \item The first level (subgoal trie) stores subgoal calls for each predicate;
  \item The second level (answer trie) stores answers for a specific subgoal.
\end{itemize}

\begin{figure}[ht]
   \centering
     \includegraphics[scale=0.6]{two_level_tries.pdf}
   \caption{Organizing the table space with tries for variant tabling.}
   \label{fig:table_space_tries}
 \end{figure}

For both levels, each trie node usually contains four fields. The first field represents the \textbf{symbol} (or \textbf{atom})
of the transition. The second points to the first descendant transition (called the \textbf{child} node)
and the third stores a pointer to the \textbf{parent} node.
The fourth field points to a \textbf{sibling} node, if any.

When the chain of sibling nodes gets too big, an hashing scheme is dynamically employed to provide direct
access to nodes, optimizing the search of transitions.

Each tabled predicate contains a \textit{table entry} that points to a \textit{subgoal trie}.
Each different call to a tabled predicate corresponds to a unique path through the subgoal trie.
Notice that for the subgoal trie only the subgoal arguments are stored.
The leaf points to a data structure called \textit{subgoal frame}. The subgoal frame stores
information about the subgoal, namely an entry point to its \textit{answer trie}.

The answer trie stores answers to the subgoal. When inserting answers only substitutions
for the variables in the call are stored. This optimization is called \textit{substitution factoring} \cite{RamakrishnanIV-95}.

Figure~\ref{fig:table_space_tries} shows the table space organization after evaluating the query goal
\texttt{path(X,Z)} for the example in Figure~\ref{fig:tabling_path}.
The figure shows how the subgoals \texttt{path(X,Z)}, \texttt{path(b,Z)} and \texttt{path(a,Z)} are
stored in the \texttt{path/2} subgoal trie and how the answer trie for \texttt{path(a,Z)} is represented.
Notice that by using substitution factoring for the answer trie, only the substitutions
\texttt{\{VAR0~=~b\}} and \texttt{\{VAR0~=~a\}} need to be stored.

\subsection{Subgoal Frames}

A subgoal frame contains general information about the state of a tabled subgoal. To access answers, this
frame contains a pointer to the root of the answer trie. A chain of answers used by consumers is also kept
in the form of head and tail pointers. In XSB, a \textit{answer return list} is built and the consumer has
a pointer to the node of the list representing the last consumed answer. In Yap, answers are chained using
the \textbf{child} pointer of the leaf answer nodes and consumers only keep the last consumed answer leaf.
The last consumed answer pointer is an \textit{answer continuation}. When a consumer needs to verify
or consume the next available answer, it uses the continuation to retrieve the next answer, following the
chain of answers. To load an answer, the trie nodes are traversed in bottom-up order and the answer is
reconstructed.

To simplify memory management, both systems link subgoal frames by storing
\textbf{next} and \textbf{previous} pointers in each subgoal frame, forming a double linked list.
The evaluation state of the subgoal is also stored. For example, Yap has the following states:
\textit{ready}, \textit{evaluating}, \textit{complete} and \textit{incomplete}.

\section{Tabling by Call Subsumption} \label{sec:subsumption}

Although variant based tabling has proven to be greatly beneficial in solving some shortcomings of the SLD resolution,
other approaches are possible. Tabling by call subsumption aims to reuse answer computations by sharing answers from
\textit{more general} goals \cite{Johnson-99}.

When a subgoal is first called, a variant engine will lookup in the table space for a variant subgoal, i.e.,
one that is identical by renaming the variables. If such a subgoal already exists on the subgoal trie, a new
consumer is created and the available answers from the variant subgoal are pushed for consumption.

Although a variant check is a light-weight operation computationally,
tabling engines using such checks can end up computing answers through program clause resolution, which takes time and space,
when they could retrieve answers from a subgoal that \textit{subsumes} the new call. By other words, a more specific subgoal
could consume answers from a general subgoal, which contains the full set of answers for the specific subgoal among the complete set.

Formally, if two subgoals $G$ and $G'$ exist, such that $S$ and $S'$ are the respective answer sets and
$G'$ subsumes $G$, then we can conclude that $S \subseteq S'$.

The effects of using subsumptive checks are greater reuse of computed answers and reduced program clause resolution, yielding
superior time performance and memory usage. In terms of memory usage, improvements can be made since fewer calls and their
associated answer sets need to be preserved \cite{Johnson-99}. However, implementing call subsumption poses various challenges:

\begin{enumerate}[(a)]
\item How to efficiently check for subsuming subgoals in the subgoal trie;
\item How to design new mechanisms to represent answers supporting fast retrieval of subsets that are only related to a subsumed call;
\item How to support incremental retrieving of the answer subset. Note that, during evaluation, it may be not possible for
the subsuming call to contain all answers, as the process of generating answers is incremental.
\end{enumerate}

For illustration purposes, in Figure~\ref{fig:tabling_path_sub}, we describe the evaluation of \texttt{path(X,Z)}
using the program presented in Figure~\ref{fig:prolog_path}
and compare it against the variant approach in Figure~\ref{fig:tabling_path}.

\begin{figure}[ht]
\centering
  \includegraphics[scale=0.6]{tabling_path_sub.pdf}
\caption{Tabling \texttt{path(X,Z)} using call by subsumption.}
\label{fig:tabling_path_sub}
\end{figure}

At step 1 the subgoal \texttt{path(X,Z)} is called and a new generator node is created as there is no existing subgoals
in the table space that could be variant or subsuming. Being a generator node, it is evaluated using the program clauses
(step 2). The first solution for the \texttt{edge(X,Y)} predicate is evaluated using Prolog's standard rules and yields
a subgoal call to \texttt{path(b,Z)} (step 3).

In variant tabling the engine would search for a variant subgoal in the table space, thus failing and creating a
new generator node, meanwhile expanding the execution tree by means of program clause resolution. In subsumptive
tabling, the engine searches for a subsuming call, and finds \texttt{path(X,Z)}. As this subgoal is more general than
\texttt{path(b,Z)} it will generate all the answers needed for the subsumed goal. A special type of consumer called a
\textit{subsumptive consumer} is thus created. This consumer knows the subsuming subgoal and can retrieve the answers
that unify with the subsumed call.

As \texttt{path(X,Z)} has no answers, no answers can be consumed by \texttt{path(b,Z)}, and thus the consumer
node is suspended and execution backtracks to node 2. The second clause of \texttt{edge/2} is tried and a new tabled
subgoal is called: \texttt{path(a,Z)} (step 4). Like \texttt{path(b,Z)}, this subgoal is subsumed by \texttt{path(X,Z)},
hence a new subsumptive consumer node is created. Execution suspends once again because no answers are available and
the engine goes back to node 1 to try the second \texttt{path/2} clause (step 5).

Answers for \texttt{path(X,Z)} are found in steps 6, \texttt{\{X~=~a,~Z~=~b\}}, and 7, \texttt{\{X~=~b,~Z~=~a\}}.
They are stored in the answer set for this subgoal. Execution thus backtracks to node 1 and completion
is attempted. Node 1 verifies that node 3 and 4 have unconsumed answers and starts by resuming computation at node 3.

Node 3 being a subsumptive consumer looks up in the \texttt{path(X,Z)} answer set for answers specific to \texttt{path(b,Z)},
finding one: \texttt{\{Z~=~a\}}. At this point, the consumer marks the answer for later retrieval, so that answers can be
immediately consumed when a variant subgoal is called. Like variant tabling, the consumer keeps a last consumed answer
continuation to know which answers have already been consumed. Variable bindings for this answer are propagated and a
new answer to \texttt{path(X,Z)} is found: \texttt{\{X~=~a,~Z~=~a\}} (step 8). Node 3 tries to consume a new answer, but no
new answers are available.

Execution suspends node 3 and resumes computation at node 4. Here \texttt{path(a,Z)} begins to consume answers from
\texttt{path(X,Z)} using the subsumption mechanism. The first answer in \texttt{path(X,Z)}, \texttt{\{X~=~a,~Z~=~b\}},
unifies with the subsumed goal and is consumed. By variable propagation, a new answer for \texttt{path(X,Z)} is also
generated, \texttt{\{X~=~b,~Z~=~b\}} (step 9). Node 3 then tries to consume a new answer and finds \texttt{\{X~=~a,~Z~=~a\}}.
This new answer is added to the \texttt{path(a,Z)} table space. As the new variable bindings are propagated, a new
answer is also generated for top subgoal, but the answer \texttt{\{X~=~b,~Z~=~a\}} is repeated (step 10), hence it
is not inserted into the table space.

Execution now suspends node 4 and resumes the the leader node, \texttt{path(X,Z)}, that will once
again attempt completion. By using the last consumed answer continuation, it verifies that node 3 has
new unconsumed answers. Execution thus resumes again at node 3.

Node 3 inspects \texttt{path(X,Z)} answer set and consumes the next matching answer, \texttt{\{X~=~b,~Z~=~b\}}.
A new answer for \texttt{path(b,Z)} is generated and variable bindings are propagated to the leader node (step 11).
However, the new answer is already stored in the table space and it is discarded.

Once again, evaluation returns to the leader node and completion is performed (step 12) as each consumer has exhausted the
available answers.

This evaluation example, when compared to variant tabling, shows a smaller execution tree with less
program clauses expanded. The subsumptive computation also took less steps to complete and a greater
reuse of answers was done between \texttt{path(X,Z)}, \texttt{path(b,Z)} and \texttt{path(a,Z)}.

Like variant tabling, the same four main operations are used when evaluating subsumptive subgoals.
These operations are very similar, with a few differences. Operations \textit{new answer} and
\textit{completion} remain the same, while the \textit{tabled subgoal call} and \textit{answer resolution}
operations work slightly differently:

\begin{itemize}
\item The \textit{tabled subgoal call} operation represents a call to a tabled subgoal.
When a subgoal $C$ is called, a search for a subsuming subgoal $C'$ is done. If such subgoal is found,
$C$ will be resolved using \textit{answer clause resolution}, thus consuming answers from $C'$.
If no subgoal $C'$ is found, then a new entry, representing $C$, is inserted into the table space and
$C$ will be evaluated using program clause resolution.

\item The \textit{answer resolution} operation checks wether new answers from the table space are
available for consumption. Each subsumptive consumer node uses an answer continuation that represents
the set of remaining answers to be consumed. Given this answer continuation, we inspect the answer trie
from the subsuming subgoal and retrieve the next answer that matches with the subsumed goal. Once the
answer is retrieved and loaded, the answer continuation is updated to reflect the new answer consumed.

\end{itemize}

% Although this example shows a very good performance of this method of evaluation, if we tried
% to evaluate \texttt{path(a,Z)} and then \texttt{path(X,Z)}, no reuse could be done with \texttt{path(a,Z)}
% because no previous subsuming goal was present. The more general subgoals are called first, the greater
% the reuse in call subsumption.

We next describe two known techniques that implement subsumptive tabling. These two approaches were
both implemented in XSB.

\subsection{Dynamic Threaded Sequential Automata}\label{sec:dtsa}

\textit{Dynamic Threaded Sequential Automata} (DTSA) is a data structure that provides good indexing
and incremental returning of a subset of answers from a subsuming call to a subsumed call \cite{Rao-96}.

This structure orders answers as they are generated, hence it can easily mark which answers were
already retrieved, enabling efficient retrieval of the remaining answers.

A DTSA is based on a \textit{Sequential Factoring Automaton} (SFA) \cite{Dawnson-95} but has a few more
features for dealing with fast indexing and incremental retrieving of answers.

\subsubsection{Sequential Factoring Automaton}

A SFA solves the problem of retrieving an ordered subset of answers, starting from the oldest to the
newest answer. It is an ordered tree-structure automaton and is very similar to a trie. It begins with
a root as the start state and has edges as transitions that represent unifications. Every leaf represents
a distinct term and the transitions on the path from the root to a leaf represent the operations necessary
to unify the goal with the term at the leaf.

Apart from ordering, SFAs differ from tries in that transitions from a state may not be unique and each
transition in a trie denotes match operations, not unify operations.

\begin{figure}[ht]
  \centering
    \includegraphics[scale=0.6]{sfa.pdf}
  \caption{Inserting answer terms in a SFA.}
  \label{fig:sfa_example}
\end{figure}

To insert a new term into a SFA, we must start by inserting symbols from the answer term into the root state.
In each state we verify if the \textit{last transition} $s$ matches the current term symbol $t$. If $t$ matches $s$
we take the transition and advance to the next state; if not, a new transition for $t$ is created and we advance
to the newly created state. When all term symbols $t$ are exhausted, the current state is marked as a leaf,
representing a new answer.
Figure~\ref{fig:sfa_example} represents a SFA for the subgoal \texttt{p(X,Y,Z)} and
illustrates insert operations.

When a new subgoal $G$ subsumed by the subgoal $G'$ is first called, we must determine the \textit{answer template}
from $G'$ to the sub-terms of $G$, because only variable substitutions are inserted into a SFA.
The answer template is usually stored under the choice point.

For example, if $G'$ is \texttt{p(X,Y,Z)} and $G$ is \texttt{p(a,a,V)}, the variable assignments
are \texttt{\{X~=~a,~Y~=~a,~Z~=~VAR0\}}. During unification operations, we must unify the first SFA symbol
to $a$, then to $a$ again, and finally with \texttt{VAR0}.
Once a variable is \textit{bound}, subsequent unify operations must unify with the bounded sub-term.

The unification process starts in the root state with an empty \textit{continuation stack}.
When a state $s$ is reached, the leftmost transition that unifies with the current $G$ assignment is chosen,
this is called the \textit{applicable transition}.
Before moving to the next state, we select the next applicable transition and push it on the continuation stack.
If no applicable transitions are available at state $s$ or if an answer was found, we pop a transition from
the stack and use it to search for more answers. Once no more transitions can be taken and the stack is empty, the
search process ends.

Using the SFA in Figure~\ref{fig:sfa_example} and the subgoal $G$, \texttt{p(a,a,V)}, the search mechanism starts
at the root state and is ready to retrieve all answers that unify with $G$.
The first applicable transition is $s1 \rightarrow s2$ because it unifies with the first symbol: $a$. The transition
$s1 \rightarrow s5$ can not be pushed into the continuation stack because it does not unify, but $s1 \rightarrow s8$ does.
In state $s2$ only one transition is available, thus nothing is pushed into the stack.
Transition $s2 \rightarrow s3$ unifies with symbol $a$ and we move to state $s3$. Here, the variable \texttt{VAR0} (that represents \texttt{V})
can unify with $a$, thus we can get to state $s4$, arriving at a leaf state and a new answer, \texttt{\{V~=~a\}}.

Next, the process must use the continuation stack to retrieve more answers. Transition $s1 \rightarrow s8$ is popped from the stack
and we arrive at state $s8$ with 3 available transitions. Using the previous rules, a new answer is retrieved,
\texttt{\{V~=~c\}} and the continuation stack contains the transition $s8 \rightarrow s13$.

Finally, once states $s13$ and $s14$ are visited, the process arrives at a leaf state and a new answer,
\texttt{\{V~=~d\}}, is retrieved. The process finishes and every answer that is specific to \texttt{p(a,a,V)} is found.

\subsubsection{Threaded Sequential Automata}

A \textit{Threaded Sequential Automata} extends the SFA with a concept called
\textit{equivalent states}. One state $S1$ is equivalent to state $S2$ if when $S1$ is taken, $S2$ is also
guaranteed to be visited. For example, in Figure~\ref{fig:sfa_example}, whenever states $s2$ and $s3$ are
visited, states $s8$ and $s9$ are also guaranteed to be visited, as they denote the same path.

A SFA is converted to a TSA by adding \textit{equivalence links} between equivalent states.
The SFA in Figure~\ref{fig:sfa_example} was transformed into a TSA in Figure~\ref{fig:tsa_example}.

\begin{figure}[ht]
  \centering
    \includegraphics[scale=0.6]{tsa.pdf}
  \caption{SFA transformed into a TSA.}
  \label{fig:tsa_example}
\end{figure}

In the TSA, the concept of applicable transitions is changed. Now it is also possible to push equivalence links
into the continuation stack as if they were normal transitions. So, if we were at state $s3$ we use
the transition to $s9$ and then to $s13$ instead of going from the start state.

Although equivalence links provide an efficient indexing mechanism, they must be used with care. If not,
some situations arise where following equivalence links lead to repeated answers and answers in the
incorrect order \cite{Rao-96}. The selection of transitions must consider only \textit{safe transitions},
which reach answers that cannot be reached through the pending transitions on the stack.
So, if the process is at state $s2$ and the transition $s1$ to $s8$ is already on the
stack, we can not use the equivalence link $s2 \rightarrow s8$, as the transition $s1 \rightarrow s8$
already covers the same branch.

If we followed only safe transitions, no equivalence links would be used, hence we must check if
the usual next applicable transition covers some answers that can not be reached from using the
equivalence links on the next branch to explore, thus favoring equivalence links. Notice that at
state $s2$ we would use the equivalence link $s2 \rightarrow s8$, instead of the transition
$s1 \rightarrow s8$, as $s2 \rightarrow s8$ will cover the same answers.
 
\subsubsection{Dynamic Threaded Sequential Automata}

The previously described mechanisms only work if we have the complete set of answers for the subsuming subgoal.
A new mechanism that deals with incomplete answer sets must be devised, so that after all current answers
are retrieved, the continuation stack can be used to retrieve newly inserted answers.

The Dynamic Threaded Sequential Automata extends the TSA with special transitions in states
were new transitions can be inserted or in states were no equivalence links exist.
Figure~\ref{fig:dtsa_example} illustrates two DTSAs: (a) shows the converted TSA from Figure~\ref{fig:tsa_example}, and
(b) the resulting DTSA after inserting the answer \texttt{p(a,b,c)}.

\begin{figure}[ht]
  \centering
    \includegraphics[scale=0.6]{dtsa.pdf}
  \caption{DTSA before and after inserting answer \texttt{p(a,b,c)}.}
  \label{fig:dtsa_example}
\end{figure}

During answer retrieval, if no answer is found and the top of the continuation stack contains
a transition to a special state, the process stops and the continuation stack is saved along the last state
visited.
Later on, when new answers must be retrieved, the last state is used to transform the stack to account for new states that
were introduced during the insertion of new terms. If the new stack contains a valid transition, it
can now be used as usual.

For example, retrieving answers to subgoal \texttt{p(a,X,c)} from the DTSA in Figure
\ref{fig:dtsa_example} (a) results in the answer \texttt{p(a,a,c)} and a continuation
formed by the last visited state $s13$ and the stack containing (from bottom to top):
$[s1~\rightarrow~v1,~s8~\rightarrow~v8,~s13~\rightarrow~v13]$.
This continuation stack contains the transitions from where it is possible that a relevant
answer will be inserted, by using either normal transitions or equivalence links.

After the new answer \texttt{p(a,b,c)} is inserted into the DTSA in Figure~\ref{fig:dtsa_example}
(b) and a consumer is resumed to consume new answers, we must check if new answers are available,
hence the continuation stack must be transformed in order to convert the virtual transitions to
instantiated transitions that may have been created after the last retrieval operation.
This stack modification is done by using the last visited state $s13$, resulting in the following
stack configuration: $[s1~\rightarrow~v1,~s8~\rightarrow~s15]$.
Now the answer \texttt{p(a,b,c)} can be easily retrieved using the transition $s8 \rightarrow s15$.
Notice that the transition $s1~\rightarrow~v1$ remains unmodified as new transitions can be created
from $s1$.

\subsubsection{Table Space Organization}

This new DTSA mechanism was implemented in XSB by extending the variant engine \cite{Rao-96}.
First, each subgoal frame now contains both an answer trie and a DTSA.
Answer tries are used to check for duplicate answers and the DTSA is created lazily, when a
subsumed subgoal is first called.

Each subsumed subgoal keeps an answer return list that is built using the DTSA retrieval algorithm.
This answer list is used when variant goals of the subsumed goal are called, thus instead of using
the DTSA, answers are retrieved directly by traversing the linked list.
When a subgoal is marked as complete, the DTSA is deleted and the answer trie is converted into WAM
instructions, a feature called \textit{compiled trie code} \cite{RamakrishnanIV-99}. Answers for
subsumed goals are then retrieved using the trie instructions through unification and backtracking.

\subsection{Time Stamped Tries} \label{sec:time_stamped_tries}

\textit{Time Stamped Tries} (TST) is another mechanism that was implemented in XSB
to support tabling by call subsumption \cite{Johnson-99}.

TST is a relatively simple technique based around the idea of augmenting a trie with information about the relative time
its terms were inserted. The time of insertion of each term is called its \textit{time stamp} and is represented by a
positive integer. The time stamps are then used for incremental answer retrieval.

For each node in a trie, we extend it by including a time stamp. Along the augmented trie, the maximum time stamp
$T$ is also stored, thus allowing the insert mechanism to know the next time stamp to use for new trie paths.
An example TST for the subgoal \texttt{p(X,Y,Z)} is represented in Figure~\ref{fig:tst_1}.
By looking at the leaf nodes, the order of answer insertion
can be readily known: \texttt{p(a,a,a)}, \texttt{p(b,a,VAR0)}, \texttt{p(a,a,c)}, \texttt{p(a,b,b)} and then
\texttt{p(a,a,d)}.

\begin{figure}[ht]
  \centering
    \includegraphics[scale=0.6]{tst_1.pdf}
  \caption{Time Stamped Trie for subgoal \texttt{p(X,Y,Z)}.}
  \label{fig:tst_1}
\end{figure}

\subsubsection{New Answers}

The process of inserting a new answer into a TST starts by traversing matching nodes as long the stored symbols
match the new answer. If the current symbol does not match, the process changes from search to insert mode and
new nodes are inserted to represent a new trie path. Once the leaf node is created, each node from leaf to root
is traversed and its time stamp is updated to $T + 1$.

\begin{figure}[ht]
  \centering
    \includegraphics[scale=0.6]{tst_2.pdf}
  \caption{Time Stamped Trie from Figure~\ref{fig:tst_1} after inserting the answer \texttt{p(a,b,c)}.}
  \label{fig:tst_2}
\end{figure}

Figure~\ref{fig:tst_2} shows the TST from Figure~\ref{fig:tst_1} after a new answer \texttt{p(a,b,c)} was inserted.
Note that each node from the answer leaf node to root node was updated with time stamp 6. Apart from
the time stamps, search and insertion in TSTs work exactly the same as standard tries.

\subsubsection{Retrieving Answers}

Retrieving all answers that are specific to a subsumed subgoal $G$ from a TST with answers from subgoal $G'$
works by navigating the TST and unifying the answers against the answer template.
If we wanted to retrieve answers to the subgoal \texttt{p(a,a,X)} from the TST in Figure~\ref{fig:tst_2},
during the subgoal call we determine the answer template relative to \texttt{path(X,Y,Z)}:
\texttt{\{X~=~a,~Y~=~a,~Z~=~VAR0\}},
and store it under the choice point. Then, the terms \texttt{[a,~a,~VAR0]} are unified
with the trie symbols, thus finding answers that are specific to $G$.

Like tries, TSTs only store substitutions for variables, thus we must unify
the first sub-term $a$, then $a$ again and then the variable, which unifies with any symbol.
During the unification process, if a variable appears multiple times, it must unify with
any previous sub-term assignment.

Time stamps guide the answer unification process by filtering transitions to already explored branches, where
answers were already retrieved, thus avoiding repeated answers.

The unification process that finds new answers by using a time stamp is separated from the process
of unifying the retrieved answers with the subsumed subgoal. This \textit{two-tier mechanism} is key to the space and time
efficiency of the design of TSTs \cite{Johnson-99} and allows identification of all relevant answers that have
been added since the last time a search operation was done by using the time stamp.

\subsubsection{Table Space Organization}

The table space in this technique extends the variant table space by
using TSTs instead of answer tries for subsuming goals.
 
Each subsumed subgoal in a call trie stores the last search time stamp $t$. The process of
incrementally searching for new answers in a TST will use $t$ and update it after the process completes.
When a subsumed subgoal is first called $t$ is set to $0$, thus initially allowing the retrieval of all
relevant answers.

The subgoal in the call trie also stores an answer return list. Each time new answers are identified, they are appended
to this linked list. The original subsumptive consumer and its variant subgoals will then consume answers from it. If no
new answers can be retrieved from the list, the TST process is employed to identify more answers from the subsuming TST,
inserting them into the list.

An hashed TST node maintains a time stamp index which stores all transitions in reverse order.
It is not until a subsumed subgoal is first called that all time stamp related structures are created, thus
allowing a more efficient use of space.

Like DTSAs, the TST indexing mechanism is only used during the evaluation of subsumed calls.
For calls with completed tables, subsumed subgoals will use compiled trie instructions from the more general subgoal.

The main advantage of using TSTs instead of DTSAs is in terms of space complexity. In TSTs, the maximum table space
used is at most twice that of the variant engine, because each node can have both the time stamp and a time stamp index node.
For DTSAs, the space used is at least double, but in the worst
case can be quadratic. DTSA is at advantage in terms of speed, because it supports identification of answers and
unification in one step, thus answers can share some elementary unifications. In TSTs, identifying answers
and doing answer unification is a two step process, thus it takes more time to construct all answers. 

\section{Chapter Summary}

In this chapter we explored how the table space is efficiently designed to support
the tabling operations in a variant or a subsumption-based engine.
For the variant engine, we presented the YapTab's table space that is based on two levels
of tries, the subgoal trie and the answer trie.

Next, we discussed the two most well-known table space organizations to implement call subsumption.
The first technique is the Dynamic Threaded Sequential Automata (DTSA). This method creates a special data
structure based on tries to efficiently collect the relevant answers for a subsumed subgoal.
The second technique is the Time Stamped Trie (TST). It improves upon the previous technique by
being simpler and having reduced space needs.

In the next chapter we will discuss the algorithms and data structures used in the TST technique,
covering the algorithm used to discover subsuming subgoals and the algorithm to collect relevant
answers. Finally, we will explain how the TST is integrated into the YapTab tabling engine to enable
call by subsumption.